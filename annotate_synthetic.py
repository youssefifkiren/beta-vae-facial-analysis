"""
Annotation Script for Synthetic Faces

This script processes synthetic faces generated by StyleGAN2 and annotates them
using the same facial feature extraction pipeline as the original FFHQ dataset.
"""

import cv2
import numpy as np
import pandas as pd
from pathlib import Path
from tqdm import tqdm
import argparse

# Load cascades
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

def extract_features(image_path):
    """Extract facial features using only face and eye detection"""
    try:
        img = cv2.imread(str(image_path))
        if img is None:
            return None
            
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # Detect face
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)
        if len(faces) == 0:
            return None
        
        # Get largest face
        x, y, w, h = max(faces, key=lambda f: f[2] * f[3])
        roi_gray = gray[y:y+h, x:x+w]
        
        # Detect eyes
        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 5)
        if len(eyes) < 2:
            return None
        
        # Get two largest eyes and sort left to right
        eyes = sorted(eyes, key=lambda e: e[2] * e[3], reverse=True)[:2]
        eyes = sorted(eyes, key=lambda e: e[0])
        left_eye = eyes[0]
        right_eye = eyes[1]
        
        # Eye centers
        left_eye_center = np.array([left_eye[0] + left_eye[2]//2, left_eye[1] + left_eye[3]//2])
        right_eye_center = np.array([right_eye[0] + right_eye[2]//2, right_eye[1] + right_eye[3]//2])
        
        # Eye distance and ratio
        eye_distance = np.linalg.norm(left_eye_center - right_eye_center)
        eye_ratio = eye_distance / w
        
        # Face aspect ratio
        face_aspect_ratio = h / w
        
        # Eye vertical position (normalized)
        avg_eye_y = (left_eye_center[1] + right_eye_center[1]) / 2
        eye_position = avg_eye_y / h
        
        # Eye size ratio (relative to face)
        avg_eye_width = (left_eye[2] + right_eye[2]) / 2
        eye_size_ratio = avg_eye_width / w
        
        # Facial symmetry (eye height difference)
        eye_height_diff = abs(left_eye_center[1] - right_eye_center[1])
        asymmetry = eye_height_diff / h
        
        # Eye angle (tilt of line connecting eyes)
        eye_angle = np.abs(np.arctan2(
            right_eye_center[1] - left_eye_center[1],
            right_eye_center[0] - left_eye_center[0]
        ))
        
        # Upper face ratio (from eyes to top)
        upper_face_ratio = avg_eye_y / h
        
        # Lower face ratio (estimated from eyes to bottom)
        lower_face_ratio = (h - avg_eye_y) / h
        
        return {
            'eye_ratio': eye_ratio,
            'face_aspect_ratio': face_aspect_ratio,
            'eye_position': eye_position,
            'eye_size_ratio': eye_size_ratio,
            'asymmetry': asymmetry,
            'eye_angle': eye_angle,
            'upper_face_ratio': upper_face_ratio,
            'lower_face_ratio': lower_face_ratio,
            'face_width': w,
            'face_height': h
        }
    except Exception as e:
        return None

def load_thresholds(annotations_csv='annotations_balanced.csv'):
    """Load percentile thresholds from original dataset"""
    df = pd.read_csv(annotations_csv)
    
    feature_cols = ['eye_ratio', 'face_aspect_ratio', 'eye_position', 
                    'eye_size_ratio', 'asymmetry', 'lower_face_ratio']
    
    thresholds = {}
    for feature in feature_cols:
        p20 = df[feature].quantile(0.20)
        p80 = df[feature].quantile(0.80)
        thresholds[f'{feature}_low'] = p20
        thresholds[f'{feature}_high'] = p80
    
    return thresholds

def assign_label(row, thresholds):
    """Assign disorder label based on facial features"""
    # Hypertelorism: Wide-set eyes
    if row['eye_ratio'] > thresholds['eye_ratio_high']:
        return 'hypertelorism'
    
    # Hypotelorism: Close-set eyes
    elif row['eye_ratio'] < thresholds['eye_ratio_low']:
        return 'hypotelorism'
    
    # Small lower face (micrognathia proxy)
    elif row['lower_face_ratio'] < thresholds['lower_face_ratio_low']:
        return 'short_lower_face'
    
    # Large lower face (prognathism)
    elif row['lower_face_ratio'] > thresholds['lower_face_ratio_high']:
        return 'long_lower_face'
    
    # Facial asymmetry
    elif row['asymmetry'] > thresholds['asymmetry_high']:
        return 'facial_asymmetry'
    
    # Normal
    else:
        return 'normal'

def main():
    parser = argparse.ArgumentParser(description='Annotate synthetic faces')
    parser.add_argument('--image-dir', type=str, default='synthetic_faces',
                      help='Directory containing synthetic images')
    parser.add_argument('--output-csv', type=str, default='synthetic_annotations.csv',
                      help='Output CSV file')
    parser.add_argument('--threshold-csv', type=str, default='annotations_balanced.csv',
                      help='CSV with original data for threshold calculation')
    
    args = parser.parse_args()
    
    print("="*60)
    print("Synthetic Face Annotation Pipeline")
    print("="*60)
    
    # Load thresholds from original dataset
    print(f"\nLoading thresholds from {args.threshold_csv}...")
    thresholds = load_thresholds(args.threshold_csv)
    print(" Thresholds loaded")
    
    # Process synthetic images
    image_dir = Path(args.image_dir)
    if not image_dir.exists():
        print(f"ERROR: Image directory not found: {args.image_dir}")
        return
    
    image_files = list(image_dir.glob('*.png'))
    print(f"\nFound {len(image_files)} images in {args.image_dir}")
    
    data = []
    failed = 0
    
    print("\nExtracting facial features...")
    for img_path in tqdm(image_files):
        features = extract_features(img_path)
        if features:
            features['image_path'] = str(img_path)
            data.append(features)
        else:
            failed += 1
    
    if len(data) == 0:
        print("ERROR: No features could be extracted!")
        print(f"Failed: {failed}/{len(image_files)} images")
        return
    
    # Create dataframe
    df = pd.DataFrame(data)
    print(f"\nSuccessfully processed: {len(df)} images")
    print(f"Failed (no face/eyes detected): {failed} images")
    print(f"Success rate: {100*len(df)/len(image_files):.1f}%")
    
    # Assign labels
    print("\nAssigning disorder labels...")
    df['label'] = df.apply(lambda row: assign_label(row, thresholds), axis=1)
    
    # Show label distribution
    print("\n" + "="*60)
    print("LABEL DISTRIBUTION")
    print("="*60)
    print(df['label'].value_counts())
    print("\nPercentages:")
    print(df['label'].value_counts(normalize=True) * 100)
    
    # Save annotations
    df.to_csv(args.output_csv, index=False)
    print(f"\n Saved annotations to {args.output_csv}")
    
    print("\n" + "="*60)
    print("NEXT STEPS")
    print("="*60)
    print("1. Merge with original training data:")
    print("   python merge_datasets.py")
    print()
    print("2. Or continue with original data only:")
    print("   python classifier_training.py")

if __name__ == '__main__':
    main()
